{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis Simple-RNNs.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1jFu9bHavrk0elTOHpQ98yKogBZf4G_h_",
          "timestamp": 1532858243515
        }
      ],
      "collapsed_sections": [
        "PMXfRsqiT-vx",
        "SrfskULvi1ik",
        "-G01YLlwQstO"
      ]
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "pUUQZSPLSrXy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "10e3bce3-4c94-4622-9f3a-3ff53fa1dc93",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532858404898,
          "user_tz": -330,
          "elapsed": 27931,
          "user": {
            "displayName": "Rohit Gujarathi",
            "photoUrl": "//lh6.googleusercontent.com/-c_7kIbjqEcI/AAAAAAAAAAI/AAAAAAAABXk/42vl1mh__Q8/s50-c-k-no/photo.jpg",
            "userId": "101035475940229498414"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gpg: keybox '/tmp/tmpw965wyn1/pubring.gpg' created\n",
            "gpg: /tmp/tmpw965wyn1/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4pv2grkESzl_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "714bede0-77ea-4ff0-87dc-ebe0d2bbdbb6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532858411324,
          "user_tz": -330,
          "elapsed": 6352,
          "user": {
            "displayName": "Rohit Gujarathi",
            "photoUrl": "//lh6.googleusercontent.com/-c_7kIbjqEcI/AAAAAAAAAAI/AAAAAAAABXk/42vl1mh__Q8/s50-c-k-no/photo.jpg",
            "userId": "101035475940229498414"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "import os\n",
        "os.chdir(\"drive/deep_learning/\")\n",
        "os.chdir(\"./sentiment_classification\")\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bow-cnn.hdf5\t\t       polar.vocab\r\n",
            "count_vectorizer_weights.hdf5  Sentiment Analysis BOW-CNN.ipynb\r\n",
            "data\t\t\t       Sentiment Analysis BOW_MLP-n-grams.ipynb\r\n",
            "data_stopwords\t\t       Sentiment Analysis Embeddings-CNN.ipynb\r\n",
            "drive\t\t\t       Sentiment Analysis Embeddings-MLP.ipynb\r\n",
            "mlpv2.py\t\t       X_test_embeddings.pkl\r\n",
            "output\t\t\t       X_train_embeddings.pkl\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PMXfRsqiT-vx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cleaning code does the following\n",
        "> convert everything to lower case\n",
        "\n",
        "> handle negations (convert \\\"don't\\\" to \\\"do not\\\")\n",
        "\n",
        "> remove tokens that are not alphabetic\n",
        "\n",
        "> filter stop words\n",
        "\n",
        "> remove tokens less than 1 character\n"
      ]
    },
    {
      "metadata": {
        "id": "WAnfDoWkTwI-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9b049ff4-62d1-4dd1-bf6c-8eb892013993",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532870842071,
          "user_tz": -330,
          "elapsed": 1067,
          "user": {
            "displayName": "Rohit Gujarathi",
            "photoUrl": "//lh6.googleusercontent.com/-c_7kIbjqEcI/AAAAAAAAAAI/AAAAAAAABXk/42vl1mh__Q8/s50-c-k-no/photo.jpg",
            "userId": "101035475940229498414"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "import os\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import keras.backend as K\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "\n",
        "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
        "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
        "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
        "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
        "                \"mustn't\":\"must not\"}\n",
        "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
        "\n",
        "def cleanv2(text):\n",
        "\t# convert to lower case\n",
        "\ttext = text.lower()\n",
        "\t# change don't to do not, doesn't to does not\n",
        "\ttext = neg_pattern.sub(lambda x: negations_dic[x.group()], text)\n",
        "\t# remove remaining tokens that are not alphabetic\n",
        "\ttext = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
        "\t# tokenize\n",
        "\ttokens = tokenizer.tokenize(text)\n",
        "\t# filter out words less than 1 character\n",
        "\ttokens = [word for word in tokens if len(word) > 1]\n",
        "\treturn tokens\t\n",
        "\n",
        "# Function to create or fetch vocabulary\n",
        "def get_vocab(vocabFile,directory='./sample'): #floyd\n",
        "\tvocabExists = os.path.isfile(vocabFile)\n",
        "\tif vocabExists:\n",
        "\t\t# Read and return vocab\n",
        "\t\tprint(\"Found vocab file {}\").format(vocabFile)\n",
        "\t\tvocab = load_doc(vocabFile)\n",
        "\t\tvocab = vocab.split('\\n')\n",
        "\t\tprint(\"Vocabulary has {} words\").format(len(vocab))\n",
        "\telse:\n",
        "\t\tprint(\"Did not find vocab file {}\").format(vocabFile)\n",
        "\t\tvocab = Counter()\n",
        "\t\t# walk through all files in the folder\n",
        "\t\tfor path, subdirs, files in os.walk(directory):\n",
        "\t\t\tfor filename in files:\n",
        "\t\t\t\t# create the full path of the file to open\n",
        "\t\t\t\tfilepath =  os.path.join(path, filename)\n",
        "\t\t\t\t# load and clean the doc\n",
        "\t\t\t\tdoc = load_doc(filepath)\n",
        "\t\t\t\ttokens = cleanv2(doc)\n",
        "\t\t\t\tvocab.update(tokens)\n",
        "\n",
        "\t\tprint(\"Number of tokens before filtering freqeuncy of occurance: {}\").format(len(vocab))\n",
        "\t\tvocab = [word for word,freq in vocab.most_common() if freq>2]\n",
        "\t\tprint(\"Number of tokens occuring more than 2 times: {}\").format(len(vocab))\n",
        "\t\t\n",
        "\t\t# Save the vocabulary file\n",
        "\t\t# convert lines to a single blob of text\n",
        "\t\tdata = '\\n'.join(vocab)\n",
        "\t\t# open file\n",
        "\t\tfile = open(vocabFile, 'w+')\n",
        "\t\t# write text\n",
        "\t\tprint(\"Saving vocabulary to {}\").format(vocabFile)\n",
        "\t\tfile.write(data)\n",
        "\t\t# close file\n",
        "\t\tfile.close()\n",
        "\treturn vocab\n",
        "\n",
        "\n",
        "# change all files to BoW representation \n",
        "# based on frequency of words in each review\n",
        "# load all docs in a directory into memory\n",
        "def process_reviews(directory,vocab):\n",
        "\treviews = list()\n",
        "\tsentiment = list()\n",
        "\t# walk through all files in the folder\n",
        "\tfor path, subdirs, files in os.walk(directory):\n",
        "\t\t\tfor filename in files:\n",
        "\t\t\t\t# create the full path of the file to open\n",
        "\t\t\t\tfilepath =  os.path.join(path, filename)\n",
        "\t\t\t\t# load the doc\n",
        "\t\t\t\tdoc = load_doc(filepath)\n",
        "\t\t\t\t# clean doc\n",
        "\t\t\t\ttokens = cleanv2(doc)\n",
        "\t\t\t\t# filter by vocab\n",
        "\t\t\t\ttokens = [word for word in tokens if word in vocab]\n",
        "\t\t\t\treview = ' '.join(tokens)\n",
        "\t\t\t\t# append review to reviews\n",
        "\t\t\t\treviews.append(review)\n",
        "\t\t\t\t# Get the sentiment as well\n",
        "\t\t\t\tsentiment.append(1 if 'pos' in filepath else 0)\n",
        "\n",
        "\treturn reviews,sentiment\n",
        "\n",
        "\n",
        "def get_data(data_file,isTrain=True):\n",
        "\tdataset_type = 'train' if isTrain else 'test'\n",
        "\tif os.path.isfile(data_file):\n",
        "\t\tprint(\"Found \"+dataset_type+\" File {}.\").format(data_file)\n",
        "\t\tdata = pickle.load(open(data_file, 'rb'))\n",
        "\t\tX,y = zip(*data)\n",
        "\n",
        "\n",
        "\telse:\n",
        "\t\tprint(\"Did not find \"+dataset_type+\" file.\")\n",
        "\t\tvocab = make_vocab('./data_stopwords/polar.vocab','./dataset/train')#floyd\n",
        "\t\tprint(\"Saved Vocabulary\")\n",
        "\t\tprint(\"processing reviews...\")\n",
        "\t\tX,y = process_reviews('./dataset/'+dataset_type,vocab) #floyd\n",
        "\t\tdata = zip(np.array(X),np.array(y))\n",
        "\t\tnp.array(data).dump('./output/'+dataset_type+'.data') #floyd\n",
        "\n",
        "\tX = np.array(X)\n",
        "\ty = np.array(y)\n",
        "\tprint(\"Found {} samples for \"+dataset_type).format(X.shape[0])\n",
        "\n",
        "\treturn X,y\n",
        "\n",
        "def ngram_tokenize(X_train,X_test,max_features=None,ngram=(1,1)):\n",
        "  from sklearn.feature_extraction.text import CountVectorizer\n",
        "  vectorizer = CountVectorizer(analyzer = \"word\", \n",
        "                               ngram_range = ngram,\n",
        "                               binary=False, # If True it is frequency else binary\n",
        "                               max_features = max_features) \n",
        "  vectorizer.fit(X_train)\n",
        "  X_train = vectorizer.transform(X_train)\n",
        "  X_test = vectorizer.transform(X_test)\n",
        "  #print vectorizer.vocabulary_\n",
        "  return X_train,X_test\n",
        "\n",
        "def train_model(model, X,y,epochs=10):\n",
        "\tfrom keras.callbacks import ModelCheckpoint\n",
        "\tX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=30)\n",
        "\tsave_model = ModelCheckpoint('weights.hdf5', monitor='val_loss',save_best_only=True)\n",
        "\thist = model.fit(X_train, y_train, batch_size=32, epochs=epochs, verbose=1, callbacks=[save_model],validation_data=(X_val,y_val),shuffle=True )\n",
        "\treturn hist\n",
        "\n",
        "def test_model(model, X_test, y_test):\n",
        "\tprint(\"Testing model on {}\").format(X_test.shape[0])\n",
        "\tmodel.load_weights('weights.hdf5') #floyd\n",
        "\tloss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "\tprint('Test Accuracy: %f' % (acc*100))\n",
        "\n",
        "def plot_loss(hist):\n",
        "\timport matplotlib.pyplot as plt\n",
        "\tloss = hist.history['loss'] #np.loadtxt('my_cnn_model_loss.csv')\n",
        "\tval_loss = hist.history['val_loss'] #np.loadtxt('my_cnn_model_val_loss.csv')\n",
        "\n",
        "\tplt.plot(loss, linewidth=3, label='train')\n",
        "\tplt.plot(val_loss, linewidth=3, label='valid')\n",
        "\tplt.grid()\n",
        "\tplt.legend()\n",
        "\tplt.xlabel('epoch')\n",
        "\tplt.ylabel('loss')\n",
        "\t#plt.ylim(1e-3, 1e-2)\n",
        "\tplt.yscale('log')\n",
        "\tplt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /content/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6Ee5eEyfNrsw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create Embeddings"
      ]
    },
    {
      "metadata": {
        "id": "mrlzbqOvEsjt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Uses sklearns LabelEncoder API for coverting words to numbers representation\n",
        "# Changed create_embeddings to get_embeddings, now we can directly fetch the embeddings\n",
        "def get_embeddingsv2(X_train,X_test,vocab_size,max_length,vocab,stop_words,file_exists):\n",
        "  \n",
        "  if file_exists:\n",
        "    print \"Fetching Data\"\n",
        "    if stop_words:\n",
        "      X_train2 = pickle.load(open('X_train_stop_words_embeddings.pkl', 'rb'))\n",
        "      X_test2 = pickle.load(open('X_test_stop_words_embeddings.pkl', 'rb'))\n",
        "    else:\n",
        "      X_train2 = pickle.load(open('X_train_embeddings.pkl', 'rb'))\n",
        "      X_test2 = pickle.load(open('X_test_embeddings.pkl', 'rb'))    \n",
        "    return X_train2,X_test2\n",
        "  \n",
        "  from sklearn.preprocessing import LabelEncoder\n",
        "  from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "  label_encoder = LabelEncoder()\n",
        "  # Remove words that are not present in the training dataset\n",
        "  #X_train_full = ' '.join(X_train)\n",
        "  #X_train_full = X_train_full.split(' ')\n",
        "  label_encoder.fit(vocab)\n",
        "  \n",
        "  print(\"Vocabulary contains {} words\").format(len(label_encoder.classes_))\n",
        "\n",
        "  print \"Encoding training data\"\n",
        "  X_train2 = []\n",
        "  for i,review in enumerate(X_train):\n",
        "    X_train2.append(label_encoder.transform(X_train[i].split(' ')))\n",
        "  \n",
        "  print \"Encoding testing data\"  \n",
        "  X_test2 = []\n",
        "  for i,review in enumerate(X_test):\n",
        "    X_test2.append(label_encoder.transform(X_test[i].split(' ')))\n",
        "    \n",
        "  print \"Padding\"\n",
        "  # pad documents to a max length\n",
        "  X_train2 = pad_sequences(X_train2, maxlen=max_length, padding='post',truncating='post')\n",
        "  X_test2 = pad_sequences(X_test2, maxlen=max_length, padding='post',truncating='post')\n",
        "  \n",
        "  print \"Saving\"\n",
        "  if stop_words:\n",
        "    np.array(X_train2).dump('X_train_stop_words_embeddings.pkl')\n",
        "    np.array(X_test2).dump('X_test_stop_words_embeddings.pkl')\n",
        "  else:\n",
        "    np.array(X_train2).dump('X_train_embeddings.pkl')\n",
        "    np.array(X_test2).dump('X_test_embeddings.pkl')\n",
        "      \n",
        "  return X_train2,X_test2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SrfskULvi1ik",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## With stop words."
      ]
    },
    {
      "metadata": {
        "id": "uYVzH2UzVvsp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "49761f33-96d8-4f07-aeb0-75849c2c92fe",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532871279185,
          "user_tz": -330,
          "elapsed": 434681,
          "user": {
            "displayName": "Rohit Gujarathi",
            "photoUrl": "//lh6.googleusercontent.com/-c_7kIbjqEcI/AAAAAAAAAAI/AAAAAAAABXk/42vl1mh__Q8/s50-c-k-no/photo.jpg",
            "userId": "101035475940229498414"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_file = './data_stopwords/train.data' #floyd\n",
        "test_file = './data_stopwords/test.data' #floyd\n",
        "vocab_file = './data_stopwords/polar.vocab'\n",
        "\n",
        "X,y = get_data(train_file,True)\n",
        "X_test,y_test = get_data(test_file,False)\n",
        "vocab = get_vocab(vocab_file)\n",
        "\n",
        "max_length = 500\n",
        "X,X_test = get_embeddingsv2(X,X_test,len(vocab),max_length,vocab,stop_words=True,file_exists=False)\n",
        "\n",
        "print(X.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found train File ./data_stopwords/train.data.\n",
            "Found 25000 samples for train\n",
            "Found test File ./data_stopwords/test.data.\n",
            "Found 25000 samples for test\n",
            "Found vocab file ./data_stopwords/polar.vocab\n",
            "Vocabulary has 37372 words\n",
            "Vocabulary contains 37372 words\n",
            "Encoding training data\n",
            "Encoding testing data\n",
            "Padding\n",
            "Saving\n",
            "(25000, 500)\n",
            "(25000, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fnyvx9VdNYRa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Trying to do many to one model"
      ]
    },
    {
      "metadata": {
        "id": "a105HlLmNWdq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Vanilla RNN"
      ]
    },
    {
      "metadata": {
        "id": "QmNnMqOCVafa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def vanilla_rnn_modelv1(input_shape):\n",
        "\n",
        "\tfrom keras.models import Model\n",
        "\tfrom keras.layers import Input, Dense, Dropout,Flatten, SimpleRNN\n",
        "\n",
        "\tinput_layer = Input(shape=(input_shape[1],input_shape[2],))\n",
        "\tx = SimpleRNN(units=32,recurrent_dropout=0.5,dropout=0.5,return_sequences=False,stateful=False)(input_layer)\n",
        "\toutput_layer = Dense(1,activation='sigmoid')(x)\n",
        "\tmodel = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "\tmodel.summary()\n",
        "\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v9lZ27aWVbgp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "556745b1-82ea-4477-f035-2d5231268d3c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532871779308,
          "user_tz": -330,
          "elapsed": 479065,
          "user": {
            "displayName": "Rohit Gujarathi",
            "photoUrl": "//lh6.googleusercontent.com/-c_7kIbjqEcI/AAAAAAAAAAI/AAAAAAAABXk/42vl1mh__Q8/s50-c-k-no/photo.jpg",
            "userId": "101035475940229498414"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X = X.reshape(X.shape[0],X.shape[1],1)\n",
        "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
        "print(X.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "model = vanilla_rnn_modelv1(input_shape=X.shape)\n",
        "\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "hist = train_model(model,X,y,epochs=2)\n",
        "test_model(model,X_test,y_test)\n",
        "plot_loss(hist)\n",
        "K.clear_session()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 500, 1)\n",
            "(25000, 500, 1)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 500, 1)            0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_3 (SimpleRNN)     (None, 32)                1088      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,121\n",
            "Trainable params: 1,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/2\n",
            " 3456/20000 [====>.........................] - ETA: 2:42 - loss: 8.1204 - acc: 0.0052"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000/20000 [==============================] - 207s 10ms/step - loss: 7.9523 - acc: 9.0000e-04 - val_loss: 7.9871 - val_acc: 0.0000e+00\n",
            "Epoch 2/2\n",
            " 7584/20000 [==========>...................] - ETA: 2:01 - loss: 7.8955 - acc: 0.0000e+00"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000/20000 [==============================] - 207s 10ms/step - loss: 7.9672 - acc: 0.0000e+00 - val_loss: 7.9871 - val_acc: 0.0000e+00\n",
            "Testing model on 25000\n",
            "Test Accuracy: 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdoAAAFYCAYAAAD0nD18AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAMImgBADCIoAUAwKD/D+CNT4ftuXyKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f120641fb50>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "e2E9BwKhNHU0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### LSTM"
      ]
    },
    {
      "metadata": {
        "id": "YzjwkyqYMNP4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def LSTM_modelv1(input_shape):\n",
        "\n",
        "\tfrom keras.models import Model\n",
        "\tfrom keras.layers import Input, Dense, Dropout,Flatten, LSTM\n",
        "\n",
        "\tinput_layer = Input(shape=(input_shape[1],input_shape[2],))\n",
        "\tx = LSTM(units=32,recurrent_dropout=0.5,dropout=0.5,return_sequences=False,stateful=False)(input_layer)\n",
        "\toutput_layer = Dense(1,activation='sigmoid')(x)\n",
        "\tmodel = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "\tmodel.summary()\n",
        "\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}